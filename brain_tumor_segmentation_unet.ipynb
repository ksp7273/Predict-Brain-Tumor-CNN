{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain Tumor Segmentation with U-Net\n",
    "\n",
    "This notebook implements a U-Net model for brain tumor segmentation using MRI images. It follows a structured pipeline: dataset setup, exploratory data analysis (EDA), plotting, data augmentation, preprocessing, image loading, data splitting, model building, training, and evaluation.\n",
    "\n",
    "**Dependencies**: TensorFlow, NumPy, Matplotlib, OpenCV, Scikit-learn\n",
    "\n",
    "**Dataset**: Assumes MRI images and binary masks in directories (e.g., `train/images`, `train/masks`). Update paths to match your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset\n",
    "\n",
    "Define paths to the dataset containing MRI images and corresponding segmentation masks. The dataset should have subdirectories for images and masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths (adjust based on your dataset structure)\n",
    "data_dir = 'path/to/dataset'\n",
    "image_dir = os.path.join(data_dir, 'images')\n",
    "mask_dir = os.path.join(data_dir, 'masks')\n",
    "\n",
    "# Image parameters\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Analyze the dataset to understand its structure, including the number of images and masks, and check for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of image and mask files\n",
    "image_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png'))]\n",
    "mask_files = [os.path.join(mask_dir, f) for f in os.listdir(mask_dir) if f.endswith(('.jpg', '.png'))]\n",
    "\n",
    "# Check dataset size and consistency\n",
    "print(f'Number of images: {len(image_files)}')\n",
    "print(f'Number of masks: {len(mask_files)}')\n",
    "assert len(image_files) == len(mask_files), 'Number of images and masks must match'\n",
    "\n",
    "# Check sample image and mask dimensions\n",
    "sample_img = cv2.imread(image_files[0])\n",
    "sample_mask = cv2.imread(mask_files[0], cv2.IMREAD_GRAYSCALE)\n",
    "print(f'Sample image shape: {sample_img.shape}')\n",
    "print(f'Sample mask shape: {sample_mask.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plot\n",
    "\n",
    "Visualize sample images and their corresponding masks to understand the data distribution and verify alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sample images and masks\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(3):\n",
    "    img = cv2.imread(image_files[i])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    mask = cv2.imread(mask_files[i], cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.title('MRI Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 3, i+4)\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.title('Mask')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Augmentation\n",
    "\n",
    "Apply data augmentation to the training images and masks to increase dataset diversity and prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_generator(img_dir, mask_dir, target_size, batch_size, augment=False):\n",
    "    if augment:\n",
    "        img_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "        mask_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "    else:\n",
    "        img_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        mask_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    img_generator = img_datagen.flow_from_directory(\n",
    "        img_dir,\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        color_mode='rgb',\n",
    "        shuffle=True,\n",
    "        seed=42\n",
    "    )\n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        mask_dir,\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        color_mode='grayscale',\n",
    "        shuffle=True,\n",
    "        seed=42\n",
    "    )\n",
    "    return zip(img_generator, mask_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing\n",
    "\n",
    "Apply preprocessing steps: convert BGR to grayscale, apply GaussianBlur, threshold, erode, dilate, and find contours to enhance images and masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH)):\n",
    "    img = cv2.imread(img_path)\n",
    "    # Convert BGR to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply GaussianBlur\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    # Apply thresholding\n",
    "    _, thresh = cv2.threshold(blurred, 127, 255, cv2.THRESH_BINARY)\n",
    "    # Erode and dilate\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    eroded = cv2.erode(thresh, kernel, iterations=1)\n",
    "    dilated = cv2.dilate(eroded, kernel, iterations=1)\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Draw contours on original image (optional, for visualization)\n",
    "    contour_img = img.copy()\n",
    "    cv2.drawContours(contour_img, contours, -1, (0, 255, 0), 2)\n",
    "    # Resize to target size\n",
    "    processed_img = cv2.resize(dilated, target_size)\n",
    "    # Convert back to 3 channels for model input\n",
    "    processed_img = cv2.cvtColor(processed_img, cv2.COLOR_GRAY2RGB)\n",
    "    processed_img = processed_img / 255.0\n",
    "    return processed_img\n",
    "\n",
    "def preprocess_mask(mask_path, target_size=(IMG_HEIGHT, IMG_WIDTH)):\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # Apply thresholding to ensure binary mask\n",
    "    _, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    # Resize to target size\n",
    "    mask = cv2.resize(mask, target_size)\n",
    "    mask = mask / 255.0\n",
    "    return mask[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Image Loading\n",
    "\n",
    "Load and preprocess images and masks using the defined preprocessing functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and masks\n",
    "images = np.array([preprocess_image(f) for f in image_files])\n",
    "masks = np.array([preprocess_mask(f) for f in mask_files])\n",
    "\n",
    "print(f'Loaded images shape: {images.shape}')\n",
    "print(f'Loaded masks shape: {masks.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Splitting (Train, Test, Validation)\n",
    "\n",
    "Split the dataset into training, validation, and test sets (e.g., 70% train, 15% validation, 15% test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(images, masks, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f'Training set: {X_train.shape[0]} images')\n",
    "print(f'Validation set: {X_val.shape[0]} images')\n",
    "print(f'Test set: {X_test.shape[0]} images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. U-Net Model Building and Training\n",
    "\n",
    "Define and train the U-Net model for segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    \n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    \n",
    "    # Bottleneck\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
    "    \n",
    "    # Decoder\n",
    "    u6 = UpSampling2D((2, 2))(c5)\n",
    "    u6 = Concatenate()([u6, c4])\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "    \n",
    "    u7 = UpSampling2D((2, 2))(c6)\n",
    "    u7 = Concatenate()([u7, c3])\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "    \n",
    "    u8 = UpSampling2D((2, 2))(c7)\n",
    "    u8 = Concatenate()([u8, c2])\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "    \n",
    "    u9 = UpSampling2D((2, 2))(c8)\n",
    "    u9 = Concatenate()([u9, c1])\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "    \n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# Create and compile model\n",
    "model = unet_model()\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Train model\n",
    "EPOCHS = 20\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluation and Visualization\n",
    "\n",
    "Evaluate the model on the test set and visualize training/validation metrics and sample predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "# Save model\n",
    "model.save('brain_tumor_unet_model.h5')\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Visualize sample predictions\n",
    "predictions = model.predict(X_test[:3])\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(3):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(X_test[i])\n",
    "    plt.title('Input Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(3, 3, i+4)\n",
    "    plt.imshow(y_test[i].squeeze(), cmap='gray')\n",
    "    plt.title('Ground Truth')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(3, 3, i+7)\n",
    "    plt.imshow(predictions[i].squeeze(), cmap='gray')\n",
    "    plt.title('Prediction')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
