{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain Tumor Classification with CNN\n",
    "\n",
    "This notebook implements a CNN for binary classification of MRI images as tumor (`yes`) or no tumor (`no`). The dataset has images in `yes` and `no` subfolders, with no masks provided.\n",
    "\n",
    "**Dependencies**: TensorFlow, NumPy, Matplotlib, OpenCV, Scikit-learn\n",
    "\n",
    "**Dataset**: MRI images in `data_dir/images/yes` and `data_dir/images/no`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset\n",
    "\n",
    "Define paths to the dataset. Images are in `images/yes` and `images/no` subfolders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths (adjust based on your dataset structure)\n",
    "data_dir = 'path/to/dataset'  # Update to your dataset path\n",
    "image_dir = os.path.join(data_dir, 'images')\n",
    "yes_dir = os.path.join(image_dir, 'yes')\n",
    "no_dir = os.path.join(image_dir, 'no')\n",
    "\n",
    "# Image parameters\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Analyze the dataset to understand the number of images in `yes` and `no` folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of image files\n",
    "yes_files = [os.path.join(yes_dir, f) for f in os.listdir(yes_dir) if f.endswith(('.jpg', '.png'))]\n",
    "no_files = [os.path.join(no_dir, f) for f in os.listdir(no_dir) if f.endswith(('.jpg', '.png'))]\n",
    "image_files = yes_files + no_files\n",
    "labels = [1] * len(yes_files) + [0] * len(no_files)  # 1 for tumor, 0 for no tumor\n",
    "\n",
    "# Check dataset size\n",
    "print(f'Number of tumor images (yes): {len(yes_files)}')\n",
    "print(f'Number of non-tumor images (no): {len(no_files)}')\n",
    "print(f'Total images: {len(image_files)}')\n",
    "\n",
    "# Check sample image dimensions\n",
    "sample_img = cv2.imread(image_files[0])\n",
    "print(f'Sample image shape: {sample_img.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plot\n",
    "\n",
    "Visualize sample images from `yes` and `no` folders to understand the data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sample images\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(3):\n",
    "    img = cv2.imread(yes_files[i] if i < len(yes_files) else no_files[i - len(yes_files)])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.title('Tumor' if i < len(yes_files) else 'No Tumor')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Augmentation\n",
    "\n",
    "Apply data augmentation to training images to increase dataset diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_generator(img_files, labels, target_size, batch_size, augment=False):\n",
    "    if augment:\n",
    "        datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "    else:\n",
    "        datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # Custom generator for images and labels\n",
    "    def flow_from_files(datagen, files, labels, target_size, batch_size, shuffle=True, seed=42):\n",
    "        while True:\n",
    "            indices = np.arange(len(files))\n",
    "            if shuffle:\n",
    "                np.random.seed(seed)\n",
    "                np.random.shuffle(indices)\n",
    "            for i in range(0, len(files), batch_size):\n",
    "                batch_indices = indices[i:i + batch_size]\n",
    "                batch_files = [files[idx] for idx in batch_indices]\n",
    "                batch_labels = [labels[idx] for idx in batch_indices]\n",
    "                batch_images = [cv2.imread(f, cv2.IMREAD_COLOR) for f in batch_files]\n",
    "                batch_images = [cv2.resize(img, target_size) for img in batch_images]\n",
    "                batch_images = np.array(batch_images) / 255.0\n",
    "                batch_labels = np.array(batch_labels)\n",
    "                yield batch_images, batch_labels\n",
    "\n",
    "    return flow_from_files(datagen, img_files, labels, target_size, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing\n",
    "\n",
    "Apply preprocessing steps: convert BGR to grayscale, apply GaussianBlur, threshold, erode, dilate, and find contours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH)):\n",
    "    img = cv2.imread(img_path)\n",
    "    # Convert BGR to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply GaussianBlur\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    # Apply thresholding\n",
    "    _, thresh = cv2.threshold(blurred, 127, 255, cv2.THRESH_BINARY)\n",
    "    # Erode and dilate\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    eroded = cv2.erode(thresh, kernel, iterations=1)\n",
    "    dilated = cv2.dilate(eroded, kernel, iterations=1)\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Draw contours on original image (for visualization)\n",
    "    contour_img = img.copy()\n",
    "    cv2.drawContours(contour_img, contours, -1, (0, 255, 0), 2)\n",
    "    # Resize to target size\n",
    "    processed_img = cv2.resize(img, target_size)  # Use original image for classification\n",
    "    processed_img = processed_img / 255.0\n",
    "    return processed_img, contour_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Image Loading\n",
    "\n",
    "Load and preprocess images from `yes` and `no` folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "images = np.array([preprocess_image(f)[0] for f in image_files])\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(f'Loaded images shape: {images.shape}')\n",
    "print(f'Loaded labels shape: {labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Splitting (Train, Test, Validation)\n",
    "\n",
    "Split the dataset into training, validation, and test sets (70% train, 15% validation, 15% test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f'Training set: {X_train.shape[0]} images')\n",
    "print(f'Validation set: {X_val.shape[0]} images')\n",
    "print(f'Test set: {X_test.shape[0]} images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. CNN Model Building and Training\n",
    "\n",
    "Define and train a CNN for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Create and compile model\n",
    "model = cnn_model()\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Train model\n",
    "EPOCHS = 20\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluation and Visualization\n",
    "\n",
    "Evaluate the model on the test set and visualize training/validation metrics and sample predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "# Save model\n",
    "model.save('brain_tumor_cnn_model.h5')\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Visualize sample predictions\n",
    "predictions = model.predict(X_test[:3])\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(X_test[i])\n",
    "    plt.title(f'Pred: {\"Tumor\" if predictions[i] > 0.5 else \"No Tumor\"}\\nTrue: {\"Tumor\" if y_test[i] == 1 else \"No Tumor\"}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
